{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the sparse representation and testing with multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import pywt\n",
    "from wavelet_preprocessing import *\n",
    "\n",
    "dataset_path = \"../data\"\n",
    "batch_size = 32\n",
    "toTensor = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "train_data = datasets.FashionMNIST(dataset_path, train=True, transform=toTensor, download=True)\n",
    "test_data = datasets.FashionMNIST(dataset_path, train=False, transform=toTensor, download=True)\n",
    "sample_data = datasets.FashionMNIST(dataset_path, train=True, transform=None, download=True)\n",
    "label_names = test_data.classes\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)\n",
    "\n",
    "PERCENTILE_THRESH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_dwt(dataset, id):\n",
    "    img, label = dataset[id]\n",
    "    img = np.array(img) # grayscale images\n",
    "    details = dec_single_level_gray_combined(img, PERCENTILE_THRESH) # zeros out anything lower than 99th percentile\n",
    "    details /= np.max(details)\n",
    "    nz_row, nz_col = np.nonzero(details)\n",
    "    print(nz_row.shape[0])\n",
    "    vec = np.zeros((nz_row.shape[0], 3))\n",
    "    count = 0\n",
    "    for idx, i in enumerate(nz_row):\n",
    "        j = nz_col[idx]\n",
    "        vec[count, 0] = details[i,j]\n",
    "        vec[count, 1] = i / details.shape[0] # normalize row and col coords between [0, 1]\n",
    "        vec[count, 2] = j / details.shape[1]\n",
    "        count += 1\n",
    "    # sort by highest value\n",
    "    vec = vec[abs(vec[:, 0]).argsort()[::-1]]\n",
    "    vec = vec.ravel()\n",
    "    if vec.shape[0] < VEC_LEN:\n",
    "        diff = VEC_LEN - vec.shape[0]\n",
    "        zeros = np.zeros((diff,))\n",
    "        vec = np.concatenate([vec, zeros]) # pad zeros to ensure\n",
    "    else:\n",
    "        vec = vec[:VEC_LEN]\n",
    "    vec = torch.Tensor(vec)\n",
    "    return vec, label\n",
    "\n",
    "def preprocess_dwt(x, vec_len, thresh):\n",
    "    x_ = torch.zeros((x.shape[0], vec_len))\n",
    "    arr = x.squeeze().cpu().data.numpy()\n",
    "    for batch, img in enumerate(arr):\n",
    "        details = dec_single_level_gray_combined(img, thresh) # zeros out anything lower than percentile\n",
    "        details /= np.max(details)\n",
    "        nz_row, nz_col = np.nonzero(details)\n",
    "        vec = np.zeros((nz_row.shape[0], 3))\n",
    "        count = 0\n",
    "        for idx, i in enumerate(nz_row):\n",
    "            j = nz_col[idx]\n",
    "            vec[count, 0] = details[i,j]\n",
    "            vec[count, 1] = i / details.shape[0] # normalize row and col coords between [0, 1]\n",
    "            vec[count, 2] = j / details.shape[1]\n",
    "            count += 1\n",
    "        # sort by highest value\n",
    "        vec = vec[abs(vec[:, 0]).argsort()[::-1]]\n",
    "        vec = vec.ravel()\n",
    "        if vec.shape[0] < vec_len:\n",
    "            diff = vec_len - vec.shape[0]\n",
    "            zeros = np.zeros((diff,))\n",
    "            vec = np.concatenate([vec, zeros]) # pad zeros to ensure\n",
    "        else:\n",
    "            vec = vec[:vec_len]\n",
    "        x_[batch, :] = torch.Tensor(vec) # add coefficients to output tensor\n",
    "    return x_\n",
    "\n",
    "def preprocess_dwt_coords(x, vec_len, thresh):\n",
    "    x_ = torch.zeros((x.shape[0], vec_len))\n",
    "    arr = x.squeeze().cpu().data.numpy()\n",
    "    for batch, img in enumerate(arr):\n",
    "        details = dec_single_level_gray_combined(img, thresh) # zeros out anything lower than percentile\n",
    "        details /= np.max(details)\n",
    "        nz_row, nz_col = np.nonzero(details)\n",
    "        vec = np.zeros((nz_row.shape[0], 3))\n",
    "        count = 0\n",
    "        for idx, i in enumerate(nz_row):\n",
    "            j = nz_col[idx]\n",
    "            vec[count, 0] = details[i,j]\n",
    "            vec[count, 1] = i / details.shape[0] # normalize row and col coords between [0, 1]\n",
    "            vec[count, 2] = j / details.shape[1]\n",
    "            count += 1\n",
    "        # sort by highest value\n",
    "        vec = vec[abs(vec[:, 0]).argsort()[::-1]]\n",
    "        vec = vec[:, 1:]\n",
    "        vec = vec.ravel()\n",
    "        if vec.shape[0] < vec_len:\n",
    "            diff = vec_len - vec.shape[0]\n",
    "            zeros = np.zeros((diff,))\n",
    "            vec = np.concatenate([vec, zeros]) # pad zeros to ensure\n",
    "        else:\n",
    "            vec = vec[:vec_len]\n",
    "        x_[batch, :] = torch.Tensor(vec) # add coefficients to output tensor\n",
    "    return x_\n",
    "\n",
    "def get_thumbnail(x):\n",
    "    x_ = torch.zeros((x.shape[0], x.shape[1], x.shape[2]//2, x.shape[3]//2))\n",
    "    arr = x.squeeze().cpu().data.numpy()\n",
    "    for batch, img in enumerate(arr):\n",
    "        details = dec_gray_thumbnail(img) # zeros out anything lower than percentile\n",
    "        x_[batch, 0, :, :] = torch.Tensor(details) # add coefficients to output tensor\n",
    "    return x_\n",
    "\n",
    "def get_sample_normal(dataset, id):\n",
    "    img, label = dataset[id]\n",
    "    img = np.array(img) # grayscale images\n",
    "    img = img.ravel()\n",
    "    vec = torch.Tensor(img)\n",
    "    return vec, label\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "    \n",
    "\n",
    "normal_loss_fn = nn.CrossEntropyLoss()\n",
    "dwt_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               dwt = False,\n",
    "               dwt_len = 50,\n",
    "               thresh = 90):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        if dwt:\n",
    "            X = preprocess_dwt(X, dwt_len, thresh)\n",
    "        # else:\n",
    "        #     X = get_thumbnail(X)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              dwt = False,\n",
    "              dwt_len = 50,\n",
    "              thresh = 90):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            if dwt:\n",
    "                X = preprocess_dwt(X, dwt_len, thresh)\n",
    "            # else:\n",
    "            #     X = get_thumbnail(X)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          dwt = False,\n",
    "          dwt_len = 100,\n",
    "          thresh = 90,\n",
    "          save: bool = False,\n",
    "          save_freq: int = 100):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "                \"test_loss\": [],\n",
    "                \"train_acc\": [],\n",
    "                 \"test_acc\": []}\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                dataloader=train_dataloader,\n",
    "                                loss_fn=loss_fn,\n",
    "                                optimizer=optimizer,\n",
    "                                dwt=dwt,\n",
    "                                dwt_len=dwt_len,\n",
    "                                thresh=thresh)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                              dataloader=test_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              dwt=dwt,\n",
    "                              dwt_len=dwt_len,\n",
    "                              thresh=thresh)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(f\"Epoch: {epoch+1}\\t| train_loss:\\t{train_loss:.5f} | train_accuracy:\\t{train_acc:.3f} | test_loss:\\t{test_loss:.5f} | test_accuracy:\\t{test_acc:.3f}\")\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        if (epoch % save_freq == 0 and epoch != 0 and save) or (epoch == epochs-1 and save):\n",
    "            torch.save(model.state_dict(), f\"../data/CNN_{epoch}_epochs.pkl\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_coords(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               dwt = False,\n",
    "               dwt_len = 50,\n",
    "               thresh = 90):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        if dwt:\n",
    "            X = preprocess_dwt_coords(X, dwt_len, thresh)\n",
    "        # else:\n",
    "        #     X = get_thumbnail(X)\n",
    "        # 1. Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "        train_acc += accuracy_fn(y, y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step_coords(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              dwt = False,\n",
    "              dwt_len = 50,\n",
    "              thresh = 90):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            if dwt:\n",
    "                X = preprocess_dwt_coords(X, dwt_len, thresh)\n",
    "            # else:\n",
    "            #     X = get_thumbnail(X)\n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy_fn(y, test_pred.argmax(dim=1))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train_coords(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          dwt = False,\n",
    "          dwt_len = 100,\n",
    "          thresh = 90,\n",
    "          save: bool = False,\n",
    "          save_freq: int = 100):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "                \"test_loss\": [],\n",
    "                \"train_acc\": [],\n",
    "                 \"test_acc\": []}\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step_coords(model=model,\n",
    "                                dataloader=train_dataloader,\n",
    "                                loss_fn=loss_fn,\n",
    "                                optimizer=optimizer,\n",
    "                                dwt=dwt,\n",
    "                                dwt_len=dwt_len,\n",
    "                                thresh=thresh)\n",
    "        test_loss, test_acc = test_step_coords(model=model,\n",
    "                              dataloader=test_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              dwt=dwt,\n",
    "                              dwt_len=dwt_len,\n",
    "                              thresh=thresh)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(f\"Epoch: {epoch+1}\\t| train_loss:\\t{train_loss:.5f} | train_accuracy:\\t{train_acc:.3f} | test_loss:\\t{test_loss:.5f} | test_accuracy:\\t{test_acc:.3f}\")\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        if (epoch % save_freq == 0 and epoch != 0 and save) or (epoch == epochs-1 and save):\n",
    "            torch.save(model.state_dict(), f\"../data/CNN_{epoch}_epochs.pkl\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t| train_loss:\t2.30118 | train_accuracy:\t16.940 | test_loss:\t2.29904 | test_accuracy:\t22.504\n",
      "Epoch: 2\t| train_loss:\t2.29229 | train_accuracy:\t25.202 | test_loss:\t2.28137 | test_accuracy:\t26.717\n",
      "Epoch: 3\t| train_loss:\t2.26940 | train_accuracy:\t28.150 | test_loss:\t2.26075 | test_accuracy:\t29.113\n",
      "Epoch: 4\t| train_loss:\t2.25286 | train_accuracy:\t30.443 | test_loss:\t2.24860 | test_accuracy:\t30.591\n",
      "Epoch: 5\t| train_loss:\t2.24228 | train_accuracy:\t31.802 | test_loss:\t2.24056 | test_accuracy:\t31.639\n",
      "Epoch: 6\t| train_loss:\t2.23655 | train_accuracy:\t31.930 | test_loss:\t2.23558 | test_accuracy:\t31.979\n",
      "Epoch: 7\t| train_loss:\t2.23115 | train_accuracy:\t32.380 | test_loss:\t2.23135 | test_accuracy:\t32.109\n",
      "Epoch: 8\t| train_loss:\t2.22864 | train_accuracy:\t32.393 | test_loss:\t2.23091 | test_accuracy:\t31.530\n",
      "Epoch: 9\t| train_loss:\t2.22487 | train_accuracy:\t32.468 | test_loss:\t2.22859 | test_accuracy:\t31.480\n",
      "Epoch: 10\t| train_loss:\t2.22393 | train_accuracy:\t32.275 | test_loss:\t2.22700 | test_accuracy:\t31.989\n"
     ]
    }
   ],
   "source": [
    "# wavelet sparse model\n",
    "epochs = 10\n",
    "vec_len = 90\n",
    "thresh = 90\n",
    "dwt_model = MLP(input_shape=vec_len, hidden_units=256, output_shape=len(label_names))\n",
    "dwt_optimizer = torch.optim.SGD(params=dwt_model.parameters(), lr=0.1)\n",
    "dwt_results = train(dwt_model, train_dataloader, test_dataloader, dwt_optimizer, dwt_loss_fn, epochs, dwt=True, dwt_len=vec_len, thresh=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m dwt_model100 \u001b[38;5;241m=\u001b[39m MLP(input_shape\u001b[38;5;241m=\u001b[39mvec_len, hidden_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, output_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(label_names))\n\u001b[1;32m      6\u001b[0m dwt_optimizer100 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(params\u001b[38;5;241m=\u001b[39mdwt_model100\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m dwt_results \u001b[38;5;241m=\u001b[39m train(dwt_model100, train_dataloader, test_dataloader, dwt_optimizer100, dwt_loss_fn, epochs, dwt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dwt_len\u001b[38;5;241m=\u001b[39mvec_len, thresh\u001b[38;5;241m=\u001b[39mthresh)\n",
      "Cell \u001b[0;32mIn [20], line 96\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, dwt, dwt_len, thresh, save, save_freq)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# 3. Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 96\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdwt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdwt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdwt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdwt_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    104\u001b[0m                           dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m    105\u001b[0m                           loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m    106\u001b[0m                           dwt\u001b[38;5;241m=\u001b[39mdwt,\n\u001b[1;32m    107\u001b[0m                           dwt_len\u001b[38;5;241m=\u001b[39mdwt_len,\n\u001b[1;32m    108\u001b[0m                           thresh\u001b[38;5;241m=\u001b[39mthresh)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# 4. Print out what's happening\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [20], line 17\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer, dwt, dwt_len, thresh)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dwt:\n\u001b[0;32m---> 17\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_dwt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdwt_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#     X = get_thumbnail(X)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 1. Forward pass\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model(X)\n",
      "Cell \u001b[0;32mIn [16], line 32\u001b[0m, in \u001b[0;36mpreprocess_dwt\u001b[0;34m(x, vec_len, thresh)\u001b[0m\n\u001b[1;32m     30\u001b[0m arr \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arr):\n\u001b[0;32m---> 32\u001b[0m     details \u001b[38;5;241m=\u001b[39m \u001b[43mdec_single_level_gray_combined\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# zeros out anything lower than percentile\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     details \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(details)\n\u001b[1;32m     34\u001b[0m     nz_row, nz_col \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(details)\n",
      "File \u001b[0;32m~/Documents/School/Fall 2023/Wavelets/final_project/F23-Wavelet-Project/wavelet_preprocessing.py:20\u001b[0m, in \u001b[0;36mdec_single_level_gray_combined\u001b[0;34m(img, percent)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdec_single_level_gray_combined\u001b[39m(img, percent):\n\u001b[1;32m     19\u001b[0m     LL, (LH, HL, HH) \u001b[38;5;241m=\u001b[39m pywt\u001b[38;5;241m.\u001b[39mdwt2(img, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb8\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiodization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpercentile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     LH[\u001b[38;5;28mabs\u001b[39m(LH) \u001b[38;5;241m<\u001b[39m p] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# zero coefficients close to 0\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(\u001b[38;5;28mabs\u001b[39m(HL), percent)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/lib/function_base.py:4134\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[1;32m   4133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentiles must be in the range [0, 100]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/lib/function_base.py:4383\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[0;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[1;32m   4375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[1;32m   4376\u001b[0m                         q,\n\u001b[1;32m   4377\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4380\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4381\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   4382\u001b[0m     \u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4383\u001b[0m     r, k \u001b[38;5;241m=\u001b[39m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4384\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4385\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4386\u001b[0m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4387\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4388\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4389\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   4391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mreshape(q\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m k)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/lib/function_base.py:3702\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3700\u001b[0m     keepdim \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m a\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m-> 3702\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/lib/function_base.py:4552\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[0;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[1;32m   4550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4551\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 4552\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4553\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4554\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4555\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4556\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/lib/function_base.py:4646\u001b[0m, in \u001b[0;36m_quantile\u001b[0;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[1;32m   4644\u001b[0m     result \u001b[38;5;241m=\u001b[39m take(arr, virtual_indexes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m   4645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4646\u001b[0m     previous_indexes, next_indexes \u001b[38;5;241m=\u001b[39m \u001b[43m_get_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4647\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mvirtual_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4648\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mvalues_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4649\u001b[0m     \u001b[38;5;66;03m# --- Sorting\u001b[39;00m\n\u001b[1;32m   4650\u001b[0m     arr\u001b[38;5;241m.\u001b[39mpartition(\n\u001b[1;32m   4651\u001b[0m         np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39mconcatenate(([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   4652\u001b[0m                                   previous_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[1;32m   4653\u001b[0m                                   next_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[1;32m   4654\u001b[0m                                   ))),\n\u001b[1;32m   4655\u001b[0m         axis\u001b[38;5;241m=\u001b[39mDATA_AXIS)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/numpy/lib/function_base.py:4573\u001b[0m, in \u001b[0;36m_get_indexes\u001b[0;34m(arr, virtual_indexes, valid_values_count)\u001b[0m\n\u001b[1;32m   4561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4562\u001b[0m \u001b[38;5;124;03mGet the valid indexes of arr neighbouring virtual_indexes.\u001b[39;00m\n\u001b[1;32m   4563\u001b[0m \u001b[38;5;124;03mNote\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4570\u001b[0m \u001b[38;5;124;03m    A Tuple of virtual_indexes neighbouring indexes\u001b[39;00m\n\u001b[1;32m   4571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4572\u001b[0m previous_indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(np\u001b[38;5;241m.\u001b[39mfloor(virtual_indexes))\n\u001b[0;32m-> 4573\u001b[0m next_indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(\u001b[43mprevious_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m)\n\u001b[1;32m   4574\u001b[0m indexes_above_bounds \u001b[38;5;241m=\u001b[39m virtual_indexes \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m valid_values_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4575\u001b[0m \u001b[38;5;66;03m# When indexes is above max index, take the max value of the array\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# wavelet sparse model\n",
    "epochs = 5\n",
    "vec_len = 196 * 3\n",
    "thresh = 0\n",
    "dwt_model100 = MLP(input_shape=vec_len, hidden_units=256, output_shape=len(label_names))\n",
    "dwt_optimizer100 = torch.optim.SGD(params=dwt_model100.parameters(), lr=0.1)\n",
    "dwt_results = train(dwt_model100, train_dataloader, test_dataloader, dwt_optimizer100, dwt_loss_fn, epochs, dwt=True, dwt_len=vec_len, thresh=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t| train_loss:\t2.30107 | train_accuracy:\t21.248 | test_loss:\t2.29869 | test_accuracy:\t27.985\n",
      "Epoch: 2\t| train_loss:\t2.29005 | train_accuracy:\t30.527 | test_loss:\t2.27664 | test_accuracy:\t33.317\n",
      "Epoch: 3\t| train_loss:\t2.26449 | train_accuracy:\t34.483 | test_loss:\t2.25450 | test_accuracy:\t33.956\n",
      "Epoch: 4\t| train_loss:\t2.24789 | train_accuracy:\t34.902 | test_loss:\t2.24261 | test_accuracy:\t34.655\n",
      "Epoch: 5\t| train_loss:\t2.23840 | train_accuracy:\t34.997 | test_loss:\t2.23598 | test_accuracy:\t34.435\n"
     ]
    }
   ],
   "source": [
    "# wavelet sparse model only coordinates\n",
    "epochs = 5\n",
    "vec_len = 90\n",
    "thresh = 85\n",
    "dwt_model2 = MLP(input_shape=vec_len, hidden_units=256, output_shape=len(label_names))\n",
    "dwt_optimizer2 = torch.optim.SGD(params=dwt_model2.parameters(), lr=0.1)\n",
    "dwt_results = train_coords(dwt_model2, train_dataloader, test_dataloader, dwt_optimizer2, dwt_loss_fn, epochs, dwt=True, dwt_len=vec_len, thresh=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t| train_loss:\t2.15524 | train_accuracy:\t63.372 | test_loss:\t2.10357 | test_accuracy:\t66.094\n",
      "Epoch: 2\t| train_loss:\t2.09134 | train_accuracy:\t68.732 | test_loss:\t2.08258 | test_accuracy:\t69.669\n",
      "Epoch: 3\t| train_loss:\t2.07890 | train_accuracy:\t71.587 | test_loss:\t2.07620 | test_accuracy:\t71.615\n",
      "Epoch: 4\t| train_loss:\t2.07479 | train_accuracy:\t72.682 | test_loss:\t2.07514 | test_accuracy:\t72.045\n",
      "Epoch: 5\t| train_loss:\t2.07279 | train_accuracy:\t73.333 | test_loss:\t2.07372 | test_accuracy:\t73.343\n",
      "Epoch: 6\t| train_loss:\t2.07074 | train_accuracy:\t74.017 | test_loss:\t2.07364 | test_accuracy:\t73.223\n",
      "Epoch: 7\t| train_loss:\t2.06991 | train_accuracy:\t74.603 | test_loss:\t2.07308 | test_accuracy:\t74.311\n",
      "Epoch: 8\t| train_loss:\t2.06887 | train_accuracy:\t75.073 | test_loss:\t2.07181 | test_accuracy:\t74.012\n",
      "Epoch: 9\t| train_loss:\t2.06854 | train_accuracy:\t75.487 | test_loss:\t2.07203 | test_accuracy:\t74.341\n",
      "Epoch: 10\t| train_loss:\t2.06771 | train_accuracy:\t75.697 | test_loss:\t2.07153 | test_accuracy:\t74.571\n"
     ]
    }
   ],
   "source": [
    "# test normal model\n",
    "epochs = 10\n",
    "normal_model = MLP(input_shape=28*28, hidden_units=512, output_shape=len(label_names))\n",
    "normal_optimizer = torch.optim.SGD(params=normal_model.parameters(), lr=0.1)\n",
    "normal_results = train(normal_model, train_dataloader, test_dataloader, normal_optimizer, normal_loss_fn, epochs, dwt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t| train_loss:\t2.14957 | train_accuracy:\t62.608 | test_loss:\t2.10397 | test_accuracy:\t65.994\n",
      "Epoch: 2\t| train_loss:\t2.09430 | train_accuracy:\t67.585 | test_loss:\t2.08690 | test_accuracy:\t68.970\n",
      "Epoch: 3\t| train_loss:\t2.08166 | train_accuracy:\t70.547 | test_loss:\t2.08167 | test_accuracy:\t70.377\n",
      "Epoch: 4\t| train_loss:\t2.07724 | train_accuracy:\t72.383 | test_loss:\t2.08101 | test_accuracy:\t70.767\n",
      "Epoch: 5\t| train_loss:\t2.07387 | train_accuracy:\t73.200 | test_loss:\t2.07623 | test_accuracy:\t71.975\n",
      "Epoch: 6\t| train_loss:\t2.07332 | train_accuracy:\t73.583 | test_loss:\t2.07281 | test_accuracy:\t73.343\n",
      "Epoch: 7\t| train_loss:\t2.07279 | train_accuracy:\t74.087 | test_loss:\t2.07557 | test_accuracy:\t73.333\n",
      "Epoch: 8\t| train_loss:\t2.07173 | train_accuracy:\t74.397 | test_loss:\t2.07392 | test_accuracy:\t73.492\n",
      "Epoch: 9\t| train_loss:\t2.07059 | train_accuracy:\t74.862 | test_loss:\t2.07394 | test_accuracy:\t74.121\n",
      "Epoch: 10\t| train_loss:\t2.07034 | train_accuracy:\t75.130 | test_loss:\t2.07346 | test_accuracy:\t73.732\n"
     ]
    }
   ],
   "source": [
    "# test normal model on thumbnail\n",
    "epochs = 10\n",
    "model_thumbnail = MLP(input_shape=14*14, hidden_units=256, output_shape=len(label_names))\n",
    "thumbnail_optimizer = torch.optim.SGD(params=model_thumbnail.parameters(), lr=0.1)\n",
    "thumbnail_results = train(model_thumbnail, train_dataloader, test_dataloader, thumbnail_optimizer, normal_loss_fn, epochs, dwt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the Describable Textures Dataset (DTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import pywt\n",
    "from wavelet_preprocessing import *\n",
    "\n",
    "dataset_path = \"../data\"\n",
    "batch_size = 16\n",
    "train_transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True), v2.Resize((240,240))])\n",
    "train_data = datasets.DTD(dataset_path, train=True, transform=train_transform, download=True)\n",
    "test_data = datasets.DTD(dataset_path, train=False, transform=train_transform, download=True)\n",
    "sample_data = datasets.DTD(dataset_path, train=True, transform=None, download=True)\n",
    "label_names = test_data.classes\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
