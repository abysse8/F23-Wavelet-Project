{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to create a custom convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseConv(Function):\n",
    "\n",
    "    # Note that forward, setup_context, and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    def forward(input, weights, width, height, in_channels, out_channels, padding, offset_row, offset_col):\n",
    "        nz = torch.nonzero(input)\n",
    "        input = torch.nn.functional.pad(input, (padding[0], padding[0], padding[1], padding[1]), 'constant', 0)\n",
    "        out = torch.zeros((input.shape[0], out_channels, height, width), dtype=torch.float32)\n",
    "        dx = torch.zeros_like(weights, dtype=torch.float32)\n",
    "        for batch in range(input.shape[0]):\n",
    "            for out_channel in range(out_channels):\n",
    "                for in_channel in range(in_channels):\n",
    "                    for n in range(nz.shape[0]):\n",
    "                        # assuming odd kernel size\n",
    "                        i = nz[n,0]\n",
    "                        j = nz[n,1]\n",
    "                        nz_window = torch.nonzero(input[batch, in_channel,\n",
    "                                        i - offset_row + padding[0]:i + offset_row+1 + padding[0],\n",
    "                                        j - offset_col + padding[1]:j + offset_col+1 + padding[1]], as_tuple=True)\n",
    "                        out[batch, out_channel, i, j] = \\\n",
    "                            torch.sum(weights[out_channel, in_channel, :, :] * \\\n",
    "                                      input[batch, in_channel,\n",
    "                                        i - offset_row + padding[0]:i + offset_row+1 + padding[0],\n",
    "                                        j - offset_col + padding[1]:j + offset_col+1 + padding[1]])\n",
    "                        \n",
    "                        dx[out_channel, in_channel, nz_window[0], nz_window[1]] += weights[out_channel, in_channel, nz_window[0], nz_window[1]]\n",
    "        \n",
    "        return out, dx\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    # inputs is a Tuple of all of the inputs passed to forward.\n",
    "    # output is the output of the forward().\n",
    "    def setup_context(ctx, inputs, out):\n",
    "        input, weights, width, height, in_channels, out_channels, padding, offset_row, offset_col = inputs\n",
    "        result, dx = out\n",
    "        ctx.in1 = width\n",
    "        ctx.in2 = height\n",
    "        ctx.in3 = in_channels\n",
    "        ctx.in4 = out_channels\n",
    "        ctx.in5 = padding\n",
    "        ctx.in6 = offset_row\n",
    "        ctx.in7 = offset_col\n",
    "        ctx.save_for_backward(input, weights, dx)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output, grad_dx):\n",
    "        input, weights, dx = ctx.saved_tensors\n",
    "        \n",
    "        grad_input = dx * grad_dx\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "# Wrap MyCube in a function so that it is clearer what the output is\n",
    "def my_sparse_conv(x, weights, width, height, in_channels, out_channels, padding, offset_row, offset_col):\n",
    "    result, dx = SparseConv.apply(x, weights, width, height, in_channels, out_channels, padding, offset_row, offset_col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "function SparseConvBackward returned an incorrect number of gradients (expected 9, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m offset_col \u001b[38;5;241m=\u001b[39m kernel_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m (x, weights, width, height, in_channels, out_channels, padding, offset_row, offset_col)\n\u001b[0;32m---> 36\u001b[0m test \u001b[38;5;241m=\u001b[39m gradcheck(my_sparse_conv, \u001b[38;5;28minput\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(test)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:2051\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gradcheck_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:2080\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2075\u001b[0m _check_outputs(outputs)\n\u001b[1;32m   2077\u001b[0m gradcheck_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2078\u001b[0m     _fast_gradcheck \u001b[38;5;28;01mif\u001b[39;00m fast_mode \u001b[38;5;28;01melse\u001b[39;00m _slow_gradcheck, masked\u001b[38;5;241m=\u001b[39mmasked\n\u001b[1;32m   2079\u001b[0m )\n\u001b[0;32m-> 2080\u001b[0m \u001b[43m_gradcheck_real_imag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradcheck_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2086\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2088\u001b[0m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_forward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_backward_ad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_undefined_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_batched_forward_grad:\n\u001b[1;32m   2097\u001b[0m     _test_batched_grad_forward_ad(func, tupled_inputs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:1482\u001b[0m, in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1469\u001b[0m         gradcheck_fn(\n\u001b[1;32m   1470\u001b[0m             real_fn,\n\u001b[1;32m   1471\u001b[0m             real_func_out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m             complex_indices\u001b[38;5;241m=\u001b[39mcomplex_out_indices,\n\u001b[1;32m   1480\u001b[0m         )\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1482\u001b[0m         \u001b[43mgradcheck_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m            \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_forward_ad:\n\u001b[1;32m   1495\u001b[0m     complex_inp_indices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1496\u001b[0m         i\n\u001b[1;32m   1497\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tupled_inputs)\n\u001b[1;32m   1498\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(inp) \u001b[38;5;129;01mand\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mis_complex()\n\u001b[1;32m   1499\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:1617\u001b[0m, in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag, masked)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputs):\n\u001b[0;32m-> 1617\u001b[0m         analytical \u001b[38;5;241m=\u001b[39m \u001b[43m_check_analytical_jacobian_attributes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtupled_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnondet_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_grad_dtypes\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j, (a, n) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(analytical, numerical[i])):\n\u001b[1;32m   1622\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _allclose_with_type_promotion(a, n\u001b[38;5;241m.\u001b[39mto(a\u001b[38;5;241m.\u001b[39mdevice), rtol, atol):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:768\u001b[0m, in \u001b[0;36m_check_analytical_jacobian_attributes\u001b[0;34m(inputs, output, nondet_tol, check_grad_dtypes, fast_mode, v)\u001b[0m\n\u001b[1;32m    766\u001b[0m     vjps2 \u001b[38;5;241m=\u001b[39m _get_analytical_vjps_wrt_specific_output(vjp_fn, output\u001b[38;5;241m.\u001b[39mclone(), v)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     vjps1 \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_analytical_jacobian_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvjp_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     vjps2 \u001b[38;5;241m=\u001b[39m _compute_analytical_jacobian_rows(vjp_fn, output\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    771\u001b[0m output_numel \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fast_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:884\u001b[0m, in \u001b[0;36m_compute_analytical_jacobian_rows\u001b[0;34m(vjp_fn, sample_output)\u001b[0m\n\u001b[1;32m    882\u001b[0m flat_grad_out\u001b[38;5;241m.\u001b[39mzero_()\n\u001b[1;32m    883\u001b[0m flat_grad_out[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m--> 884\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_out_base\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d_x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(grad_inputs):\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/gradcheck.py:759\u001b[0m, in \u001b[0;36m_check_analytical_jacobian_attributes.<locals>.vjp_fn\u001b[0;34m(grad_output)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp_fn\u001b[39m(grad_output):\n\u001b[0;32m--> 759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_input_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/autograd/__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    391\u001b[0m         grad_outputs_\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    405\u001b[0m         output\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[1;32m    409\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: function SparseConvBackward returned an incorrect number of gradients (expected 9, got 1)"
     ]
    }
   ],
   "source": [
    "from torch.autograd import gradcheck\n",
    "\n",
    "def calculateNewWidth(self, x):\n",
    "    return (\n",
    "        (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "        // self.stride[0]\n",
    "    ) + 1\n",
    "\n",
    "def calculateNewHeight(self, x):\n",
    "    return (\n",
    "        (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "        // self.stride[1]\n",
    "    ) + 1\n",
    "# gradcheck takes a tuple of tensors as input, check if your gradient\n",
    "# evaluated with these tensors are close enough to numerical\n",
    "# approximations and returns True if they all verify this condition.\n",
    "x = torch.eye(10, requires_grad=True, dtype=torch.double).unsqueeze(0).unsqueeze(0)\n",
    "weights = torch.randn((1,1,5,5), requires_grad=True, dtype=torch.double)\n",
    "padding = (2,2)\n",
    "dilation = (1,1)\n",
    "kernel_size = (5,5)\n",
    "stride = (1,1)\n",
    "width = (\n",
    "        (x.shape[2] + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1)\n",
    "        // stride[0]\n",
    "    ) + 1\n",
    "height = (\n",
    "        (x.shape[3] + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1)\n",
    "        // stride[1]\n",
    "    ) + 1\n",
    "in_channels = 1\n",
    "out_channels = 1\n",
    "offset_row = kernel_size[0] // 2\n",
    "offset_col = kernel_size[1] // 2\n",
    "input = (x, weights, width, height, in_channels, out_channels, padding, offset_row, offset_col)\n",
    "test = gradcheck(my_sparse_conv, input, eps=1e-6, atol=1e-4)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [2, 2]])\n",
      "tensor([0, 1, 2]) tensor([0, 1, 2])\n",
      "tensor([[[2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.eye(9).unsqueeze(0)\n",
    "print(torch.nonzero(temp[0, 3:6,3:6]))\n",
    "nz = torch.nonzero(temp[0, 3:6,3:6], as_tuple=True)\n",
    "print(nz[0], nz[1])\n",
    "temp[0, nz[0], nz[1]] += temp[0, nz[0], nz[1]]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1):\n",
    "        super(sparseConv2D, self).__init__()\n",
    "        \n",
    "        self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_size_number = kernel_size * kernel_size\n",
    "        self.offset_row = self.kernel_size[0] // 2\n",
    "        self.offset_col = self.kernel_size[1] // 2\n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = (dilation, dilation)\n",
    "        self.padding = (padding, padding)\n",
    "        self.stride = (stride, stride)\n",
    "        self.in_channels = in_channels\n",
    "        self.weights = nn.Parameter(torch.randn((self.out_channels, self.in_channels, self.kernel_size[0], self.kernel_size[1])))\n",
    "        self.register_parameter(\"kernels\", self.weights)\n",
    "        # self.weights.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # nz = torch.nonzero(x)\n",
    "        # width = self.calculateNewWidth(x)\n",
    "        # height = self.calculateNewHeight(x)\n",
    "        # x = torch.nn.functional.pad(x, (self.padding[0], self.padding[0], self.padding[1], self.padding[1]), 'constant', 0)\n",
    "        # out = torch.zeros((x.shape[0], self.out_channels, height, width), dtype=torch.float32)\n",
    "        # for batch in range(x.shape[0]):\n",
    "        #     for out_channel in range(self.out_channels):\n",
    "        #         for in_channel in range(self.in_channels):\n",
    "        #             for n in range(nz.shape[0]):\n",
    "        #                 # assuming odd kernel size\n",
    "        #                 i = nz[n,0]\n",
    "        #                 j = nz[n,1]\n",
    "        #                 out[batch, out_channel, i, j] = \\\n",
    "        #                     torch.sum(self.weights[out_channel, in_channel, :, :] * \\\n",
    "        #                               x[batch, in_channel,\n",
    "        #                                 i - self.offset_row + self.padding[0]:i + self.offset_row+1 + self.padding[0],\n",
    "        #                                 j - self.offset_col + self.padding[1]:j + self.offset_col+1 + self.padding[1]])\n",
    "        \n",
    "        # x = out\n",
    "        # return x\n",
    "\n",
    "    def calculateNewWidth(self, x):\n",
    "        return (\n",
    "            (x.shape[2] + 2 * self.padding[0] - self.dilation[0] * (self.kernel_size[0] - 1) - 1)\n",
    "            // self.stride[0]\n",
    "        ) + 1\n",
    "\n",
    "    def calculateNewHeight(self, x):\n",
    "        return (\n",
    "            (x.shape[3] + 2 * self.padding[1] - self.dilation[1] * (self.kernel_size[1] - 1) - 1)\n",
    "            // self.stride[1]\n",
    "        ) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparseCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sparseCNN, self).__init__()\n",
    "        self.conv1 = sparseConv2D(in_channels=1, \n",
    "                                  out_channels=1, \n",
    "                                  kernel_size=5, \n",
    "                                  dilation=1, \n",
    "                                  padding=2, \n",
    "                                  stride=1)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        # self.linear = nn.Linear(10*14*14, 10)\n",
    "        # self.out = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.flatten(x)\n",
    "        # x = self.linear(x)\n",
    "        # x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.5391,  1.0129, -0.5719,  0.0184, -1.2213],\n",
      "          [-1.5627, -0.2636, -1.5103, -0.2849, -0.2953],\n",
      "          [-0.7283, -1.0078,  1.6991, -0.3756, -0.4482],\n",
      "          [ 0.8908, -2.1303, -0.5394,  1.1742,  0.5946],\n",
      "          [-0.5012, -0.2617, -0.0962,  0.3924,  0.4818]]]], requires_grad=True)\n",
      "Loss:  8.163265228271484\n",
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]]])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.5391,  1.0129, -0.5719,  0.0184, -1.2213],\n",
      "          [-1.5627, -0.2636, -1.5103, -0.2849, -0.2953],\n",
      "          [-0.7283, -1.0078,  1.6991, -0.3756, -0.4482],\n",
      "          [ 0.8908, -2.1303, -0.5394,  1.1742,  0.5946],\n",
      "          [-0.5012, -0.2617, -0.0962,  0.3924,  0.4818]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = sparseCNN()\n",
    "net.train()\n",
    "optimizer = torch.optim.SGD(params=net.parameters(), lr=0.1)\n",
    "loss = nn.MSELoss()\n",
    "out = torch.zeros((1,1,14,14))\n",
    "out[0,0,7:11,7:11] = 10\n",
    "inp = torch.zeros((1,1,14,14))\n",
    "inp[0,:,7,7] = 1\n",
    "\n",
    "print(net.conv1.weights)\n",
    "for i in range(1):\n",
    "    pred = net.forward(inp)\n",
    "    l = loss(pred, out)\n",
    "    print(\"Loss: \", l.item())\n",
    "    # l.requires_grad = True\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    print(net.conv1.weights.grad)\n",
    "print(net.conv1.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-2.8262,  0.9700,  0.7905,  1.0629,  2.0799],\n",
      "          [ 1.0917,  0.6226, -1.4012, -0.6333, -1.1871],\n",
      "          [ 0.7901, -0.7102,  1.1423,  0.4486, -0.8829],\n",
      "          [-0.0178,  0.1736,  0.5451, -0.0836, -0.9699],\n",
      "          [-0.2646, -0.5052, -0.4009,  0.8752,  0.0299]]]], requires_grad=True)]\n",
      "tensor([[[[0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(list(net.parameters()))\n",
    "print(net.conv1.weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 1, 1])\n",
      "torch.Size([3, 5, 6])\n",
      "tensor(7)\n",
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0.],\n",
      "        [0., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(3*4*5*6).view(3,4,5,6)\n",
    "print(t.sum(dim=(2,3), keepdim=True).shape)\n",
    "print(t[:,0,:,:].shape)\n",
    "idx = torch.tensor([[1,1],[2,2]])\n",
    "print(t[0,0,1,1])\n",
    "\n",
    "from torch.nn.functional import pad\n",
    "o = torch.ones((4,4))\n",
    "print(pad(o, (1,1,1,1), \"constant\", 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
